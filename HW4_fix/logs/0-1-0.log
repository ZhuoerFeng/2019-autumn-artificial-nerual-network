VGG16 weights loaded
e:0/100, 100 loss: 0.000 acc: 0.000000
e:0/100, 200 loss: 0.000 acc: 0.000000
e:0/100, 300 loss: 0.000 acc: 0.000000
e:0/100, 400 loss: 0.000 acc: 0.000000
e:0/100, 500 loss: 0.000 acc: 0.000000
Training for batch 0 is done
e:1/100, 100 loss: 0.000 acc: 0.000000
e:1/100, 200 loss: 0.000 acc: 0.000000
e:1/100, 300 loss: 0.000 acc: 0.000000
e:1/100, 400 loss: 0.000 acc: 0.000000
e:1/100, 500 loss: 0.000 acc: 0.000000
Training for batch 1 is done
e:2/100, 100 loss: 0.000 acc: 0.000000
e:2/100, 200 loss: 0.000 acc: 0.000000
e:2/100, 300 loss: 0.000 acc: 0.000000
e:2/100, 400 loss: 0.000 acc: 0.000000
e:2/100, 500 loss: 0.000 acc: 0.000000
Training for batch 2 is done
e:3/100, 100 loss: 0.000 acc: 0.000000
e:3/100, 200 loss: 0.000 acc: 0.000000
e:3/100, 300 loss: 0.000 acc: 0.000000
e:3/100, 400 loss: 0.000 acc: 0.000000
e:3/100, 500 loss: 0.000 acc: 0.000000
Training for batch 3 is done
e:4/100, 100 loss: 0.000 acc: 0.000000
e:4/100, 200 loss: 0.000 acc: 0.000000
e:4/100, 300 loss: 0.000 acc: 0.000000
e:4/100, 400 loss: 0.000 acc: 0.000000
e:4/100, 500 loss: 0.000 acc: 0.000000
Training for batch 4 is done
e:5/100, 100 loss: 0.000 acc: 0.000000
e:5/100, 200 loss: 0.000 acc: 0.000000
e:5/100, 300 loss: 0.000 acc: 0.000000
e:5/100, 400 loss: 0.000 acc: 0.000000
e:5/100, 500 loss: 0.000 acc: 0.000000
Training for batch 5 is done
e:6/100, 100 loss: 0.000 acc: 0.000000
e:6/100, 200 loss: 0.000 acc: 0.000000
e:6/100, 300 loss: 0.000 acc: 0.000000
e:6/100, 400 loss: 0.000 acc: 0.000000
e:6/100, 500 loss: 0.000 acc: 0.000000
Training for batch 6 is done
e:7/100, 100 loss: 0.000 acc: 0.000000
e:7/100, 200 loss: 0.000 acc: 0.000000
e:7/100, 300 loss: 0.000 acc: 0.000000
e:7/100, 400 loss: 0.000 acc: 0.000000
e:7/100, 500 loss: 0.000 acc: 0.000000
Training for batch 7 is done
e:8/100, 100 loss: 0.000 acc: 0.000000
e:8/100, 200 loss: 0.000 acc: 0.000000
e:8/100, 300 loss: 0.000 acc: 0.000000
e:8/100, 400 loss: 0.000 acc: 0.000000
e:8/100, 500 loss: 0.000 acc: 0.000000
Training for batch 8 is done
e:9/100, 100 loss: 0.000 acc: 0.000000
e:9/100, 200 loss: 0.000 acc: 0.000000
e:9/100, 300 loss: 0.000 acc: 0.000000
e:9/100, 400 loss: 0.000 acc: 0.000000
e:9/100, 500 loss: 0.000 acc: 0.000000
Training for batch 9 is done
e:10/100, 100 loss: 0.000 acc: 0.000000
e:10/100, 200 loss: 0.000 acc: 0.000000
e:10/100, 300 loss: 0.000 acc: 0.000000
e:10/100, 400 loss: 0.000 acc: 0.000000
e:10/100, 500 loss: 0.000 acc: 0.000000
Training for batch 10 is done
e:11/100, 100 loss: 0.000 acc: 0.000000
e:11/100, 200 loss: 0.000 acc: 0.000000
e:11/100, 300 loss: 0.000 acc: 0.000000
e:11/100, 400 loss: 0.000 acc: 0.000000
e:11/100, 500 loss: 0.000 acc: 0.000000
Training for batch 11 is done
e:12/100, 100 loss: 0.000 acc: 0.000000
e:12/100, 200 loss: 0.000 acc: 0.000000
e:12/100, 300 loss: 0.000 acc: 0.000000
e:12/100, 400 loss: 0.000 acc: 0.000000
e:12/100, 500 loss: 0.000 acc: 0.000000
Training for batch 12 is done
e:13/100, 100 loss: 0.000 acc: 0.000000
e:13/100, 200 loss: 0.000 acc: 0.000000
e:13/100, 300 loss: 0.000 acc: 0.000000
e:13/100, 400 loss: 0.000 acc: 0.000000
e:13/100, 500 loss: 0.000 acc: 0.000000
Training for batch 13 is done
e:14/100, 100 loss: 0.000 acc: 0.000000
e:14/100, 200 loss: 0.000 acc: 0.000000
e:14/100, 300 loss: 0.000 acc: 0.000000
e:14/100, 400 loss: 0.000 acc: 0.000000
e:14/100, 500 loss: 0.000 acc: 0.000000
Training for batch 14 is done
e:15/100, 100 loss: 0.000 acc: 0.000000
e:15/100, 200 loss: 0.000 acc: 0.000000
e:15/100, 300 loss: 0.000 acc: 0.000000
e:15/100, 400 loss: 0.000 acc: 0.000000
e:15/100, 500 loss: 0.000 acc: 0.000000
Training for batch 15 is done
e:16/100, 100 loss: 0.000 acc: 0.000000
e:16/100, 200 loss: 0.000 acc: 0.000000
e:16/100, 300 loss: 0.000 acc: 0.000000
e:16/100, 400 loss: 0.000 acc: 0.000000
e:16/100, 500 loss: 0.000 acc: 0.000000
Training for batch 16 is done
e:17/100, 100 loss: 0.000 acc: 0.000000
e:17/100, 200 loss: 0.000 acc: 0.000000
e:17/100, 300 loss: 0.000 acc: 0.000000
e:17/100, 400 loss: 0.000 acc: 0.000000
e:17/100, 500 loss: 0.000 acc: 0.000000
Training for batch 17 is done
e:18/100, 100 loss: 0.000 acc: 0.000000
e:18/100, 200 loss: 0.000 acc: 0.000000
e:18/100, 300 loss: 0.000 acc: 0.000000
e:18/100, 400 loss: 0.000 acc: 0.000000
e:18/100, 500 loss: 0.000 acc: 0.000000
Training for batch 18 is done
e:19/100, 100 loss: 0.000 acc: 0.000000
e:19/100, 200 loss: 0.000 acc: 0.000000
e:19/100, 300 loss: 0.000 acc: 0.000000
e:19/100, 400 loss: 0.000 acc: 0.000000
e:19/100, 500 loss: 0.000 acc: 0.000000
Training for batch 19 is done
e:20/100, 100 loss: 0.000 acc: 0.000000
e:20/100, 200 loss: 0.000 acc: 0.000000
e:20/100, 300 loss: 0.000 acc: 0.000000
e:20/100, 400 loss: 0.000 acc: 0.000000
e:20/100, 500 loss: 0.000 acc: 0.000000
Training for batch 20 is done
e:21/100, 100 loss: 0.000 acc: 0.000000
e:21/100, 200 loss: 0.000 acc: 0.000000
e:21/100, 300 loss: 0.000 acc: 0.000000
e:21/100, 400 loss: 0.000 acc: 0.000000
e:21/100, 500 loss: 0.000 acc: 0.000000
Training for batch 21 is done
e:22/100, 100 loss: 0.000 acc: 0.000000
e:22/100, 200 loss: 0.000 acc: 0.000000
e:22/100, 300 loss: 0.000 acc: 0.000000
e:22/100, 400 loss: 0.000 acc: 0.000000
e:22/100, 500 loss: 0.000 acc: 0.000000
Training for batch 22 is done
e:23/100, 100 loss: 0.000 acc: 0.000000
e:23/100, 200 loss: 0.000 acc: 0.000000
e:23/100, 300 loss: 0.000 acc: 0.000000
e:23/100, 400 loss: 0.000 acc: 0.000000
e:23/100, 500 loss: 0.000 acc: 0.000000
Training for batch 23 is done
e:24/100, 100 loss: 0.000 acc: 0.000000
e:24/100, 200 loss: 0.000 acc: 0.000000
e:24/100, 300 loss: 0.000 acc: 0.000000
e:24/100, 400 loss: 0.000 acc: 0.000000
e:24/100, 500 loss: 0.000 acc: 0.000000
Training for batch 24 is done
e:25/100, 100 loss: 0.000 acc: 0.000000
e:25/100, 200 loss: 0.000 acc: 0.000000
e:25/100, 300 loss: 0.000 acc: 0.000000
e:25/100, 400 loss: 0.000 acc: 0.000000
e:25/100, 500 loss: 0.000 acc: 0.000000
Training for batch 25 is done
e:26/100, 100 loss: 0.000 acc: 0.000000
e:26/100, 200 loss: 0.000 acc: 0.000000
e:26/100, 300 loss: 0.000 acc: 0.000000
e:26/100, 400 loss: 0.000 acc: 0.000000
e:26/100, 500 loss: 0.000 acc: 0.000000
Training for batch 26 is done
e:27/100, 100 loss: 0.000 acc: 0.000000
e:27/100, 200 loss: 0.000 acc: 0.000000
e:27/100, 300 loss: 0.000 acc: 0.000000
e:27/100, 400 loss: 0.000 acc: 0.000000
e:27/100, 500 loss: 0.000 acc: 0.000000
Training for batch 27 is done
e:28/100, 100 loss: 0.000 acc: 0.000000
e:28/100, 200 loss: 0.000 acc: 0.000000
e:28/100, 300 loss: 0.000 acc: 0.000000
e:28/100, 400 loss: 0.000 acc: 0.000000
e:28/100, 500 loss: 0.000 acc: 0.000000
Training for batch 28 is done
e:29/100, 100 loss: 0.000 acc: 0.000000
e:29/100, 200 loss: 0.000 acc: 0.000000
e:29/100, 300 loss: 0.000 acc: 0.000000
e:29/100, 400 loss: 0.000 acc: 0.000000
e:29/100, 500 loss: 0.000 acc: 0.000000
Training for batch 29 is done
e:30/100, 100 loss: 0.000 acc: 0.000000
e:30/100, 200 loss: 0.000 acc: 0.000000
e:30/100, 300 loss: 0.000 acc: 0.000000
e:30/100, 400 loss: 0.000 acc: 0.000000
e:30/100, 500 loss: 0.000 acc: 0.000000
Training for batch 30 is done
e:31/100, 100 loss: 0.000 acc: 0.000000
e:31/100, 200 loss: 0.000 acc: 0.000000
e:31/100, 300 loss: 0.000 acc: 0.000000
e:31/100, 400 loss: 0.000 acc: 0.000000
e:31/100, 500 loss: 0.000 acc: 0.000000
Training for batch 31 is done
e:32/100, 100 loss: 0.000 acc: 0.000000
e:32/100, 200 loss: 0.000 acc: 0.000000
e:32/100, 300 loss: 0.000 acc: 0.000000
e:32/100, 400 loss: 0.000 acc: 0.000000
e:32/100, 500 loss: 0.000 acc: 0.000000
Training for batch 32 is done
e:33/100, 100 loss: 0.000 acc: 0.000000
e:33/100, 200 loss: 0.000 acc: 0.000000
e:33/100, 300 loss: 0.000 acc: 0.000000
e:33/100, 400 loss: 0.000 acc: 0.000000
e:33/100, 500 loss: 0.000 acc: 0.000000
Training for batch 33 is done
e:34/100, 100 loss: 0.000 acc: 0.000000
e:34/100, 200 loss: 0.000 acc: 0.000000
e:34/100, 300 loss: 0.000 acc: 0.000000
e:34/100, 400 loss: 0.000 acc: 0.000000
e:34/100, 500 loss: 0.000 acc: 0.000000
Training for batch 34 is done
e:35/100, 100 loss: 0.000 acc: 0.000000
e:35/100, 200 loss: 0.000 acc: 0.000000
e:35/100, 300 loss: 0.000 acc: 0.000000
e:35/100, 400 loss: 0.000 acc: 0.000000
e:35/100, 500 loss: 0.000 acc: 0.000000
Training for batch 35 is done
e:36/100, 100 loss: 0.000 acc: 0.000000
e:36/100, 200 loss: 0.000 acc: 0.000000
e:36/100, 300 loss: 0.000 acc: 0.000000
e:36/100, 400 loss: 0.000 acc: 0.000000
e:36/100, 500 loss: 0.000 acc: 0.000000
Training for batch 36 is done
e:37/100, 100 loss: 0.000 acc: 0.000000
e:37/100, 200 loss: 0.000 acc: 0.000000
e:37/100, 300 loss: 0.000 acc: 0.000000
e:37/100, 400 loss: 0.000 acc: 0.000000
e:37/100, 500 loss: 0.000 acc: 0.000000
Training for batch 37 is done
e:38/100, 100 loss: 0.000 acc: 0.000000
e:38/100, 200 loss: 0.000 acc: 0.000000
e:38/100, 300 loss: 0.000 acc: 0.000000
e:38/100, 400 loss: 0.000 acc: 0.000000
e:38/100, 500 loss: 0.000 acc: 0.000000
Training for batch 38 is done
e:39/100, 100 loss: 0.000 acc: 0.000000
e:39/100, 200 loss: 0.000 acc: 0.000000
e:39/100, 300 loss: 0.000 acc: 0.000000
e:39/100, 400 loss: 0.000 acc: 0.000000
e:39/100, 500 loss: 0.000 acc: 0.000000
Training for batch 39 is done
e:40/100, 100 loss: 0.000 acc: 0.000000
e:40/100, 200 loss: 0.000 acc: 0.000000
e:40/100, 300 loss: 0.000 acc: 0.000000
e:40/100, 400 loss: 0.000 acc: 0.000000
e:40/100, 500 loss: 0.000 acc: 0.000000
Training for batch 40 is done
e:41/100, 100 loss: 0.000 acc: 0.000000
e:41/100, 200 loss: 0.000 acc: 0.000000
e:41/100, 300 loss: 0.000 acc: 0.000000
e:41/100, 400 loss: 0.000 acc: 0.000000
e:41/100, 500 loss: 0.000 acc: 0.000000
Training for batch 41 is done
e:42/100, 100 loss: 0.000 acc: 0.000000
e:42/100, 200 loss: 0.000 acc: 0.000000
e:42/100, 300 loss: 0.000 acc: 0.000000
e:42/100, 400 loss: 0.000 acc: 0.000000
e:42/100, 500 loss: 0.000 acc: 0.000000
Training for batch 42 is done
e:43/100, 100 loss: 0.000 acc: 0.000000
e:43/100, 200 loss: 0.000 acc: 0.000000
e:43/100, 300 loss: 0.000 acc: 0.000000
e:43/100, 400 loss: 0.000 acc: 0.000000
e:43/100, 500 loss: 0.000 acc: 0.000000
Training for batch 43 is done
e:44/100, 100 loss: 0.000 acc: 0.000000
e:44/100, 200 loss: 0.000 acc: 0.000000
e:44/100, 300 loss: 0.000 acc: 0.000000
e:44/100, 400 loss: 0.000 acc: 0.000000
e:44/100, 500 loss: 0.000 acc: 0.000000
Training for batch 44 is done
e:45/100, 100 loss: 0.000 acc: 0.000000
e:45/100, 200 loss: 0.000 acc: 0.000000
e:45/100, 300 loss: 0.000 acc: 0.000000
e:45/100, 400 loss: 0.000 acc: 0.000000
e:45/100, 500 loss: 0.000 acc: 0.000000
Training for batch 45 is done
e:46/100, 100 loss: 0.000 acc: 0.000000
e:46/100, 200 loss: 0.000 acc: 0.000000
e:46/100, 300 loss: 0.000 acc: 0.000000
e:46/100, 400 loss: 0.000 acc: 0.000000
e:46/100, 500 loss: 0.000 acc: 0.000000
Training for batch 46 is done
e:47/100, 100 loss: 0.000 acc: 0.000000
e:47/100, 200 loss: 0.000 acc: 0.000000
e:47/100, 300 loss: 0.000 acc: 0.000000
e:47/100, 400 loss: 0.000 acc: 0.000000
e:47/100, 500 loss: 0.000 acc: 0.000000
Training for batch 47 is done
e:48/100, 100 loss: 0.000 acc: 0.000000
e:48/100, 200 loss: 0.000 acc: 0.000000
e:48/100, 300 loss: 0.000 acc: 0.000000
e:48/100, 400 loss: 0.000 acc: 0.000000
e:48/100, 500 loss: 0.000 acc: 0.000000
Training for batch 48 is done
e:49/100, 100 loss: 0.000 acc: 0.000000
e:49/100, 200 loss: 0.000 acc: 0.000000
e:49/100, 300 loss: 0.000 acc: 0.000000
e:49/100, 400 loss: 0.000 acc: 0.000000
e:49/100, 500 loss: 0.000 acc: 0.000000
Training for batch 49 is done
e:50/100, 100 loss: 0.000 acc: 0.000000
e:50/100, 200 loss: 0.000 acc: 0.000000
e:50/100, 300 loss: 0.000 acc: 0.000000
e:50/100, 400 loss: 0.000 acc: 0.000000
e:50/100, 500 loss: 0.000 acc: 0.000000
Training for batch 50 is done
e:51/100, 100 loss: 0.000 acc: 0.000000
e:51/100, 200 loss: 0.000 acc: 0.000000
e:51/100, 300 loss: 0.000 acc: 0.000000
e:51/100, 400 loss: 0.000 acc: 0.000000
e:51/100, 500 loss: 0.000 acc: 0.000000
Training for batch 51 is done
e:52/100, 100 loss: 0.000 acc: 0.000000
e:52/100, 200 loss: 0.000 acc: 0.000000
e:52/100, 300 loss: 0.000 acc: 0.000000
e:52/100, 400 loss: 0.000 acc: 0.000000
e:52/100, 500 loss: 0.000 acc: 0.000000
Training for batch 52 is done
e:53/100, 100 loss: 0.000 acc: 0.000000
e:53/100, 200 loss: 0.000 acc: 0.000000
e:53/100, 300 loss: 0.000 acc: 0.000000
e:53/100, 400 loss: 0.000 acc: 0.000000
e:53/100, 500 loss: 0.000 acc: 0.000000
Training for batch 53 is done
e:54/100, 100 loss: 0.000 acc: 0.000000
e:54/100, 200 loss: 0.000 acc: 0.000000
e:54/100, 300 loss: 0.000 acc: 0.000000
e:54/100, 400 loss: 0.000 acc: 0.000000
e:54/100, 500 loss: 0.000 acc: 0.000000
Training for batch 54 is done
e:55/100, 100 loss: 0.000 acc: 0.000000
e:55/100, 200 loss: 0.000 acc: 0.000000
e:55/100, 300 loss: 0.000 acc: 0.000000
e:55/100, 400 loss: 0.000 acc: 0.000000
e:55/100, 500 loss: 0.000 acc: 0.000000
Training for batch 55 is done
e:56/100, 100 loss: 0.000 acc: 0.000000
e:56/100, 200 loss: 0.000 acc: 0.000000
e:56/100, 300 loss: 0.000 acc: 0.000000
e:56/100, 400 loss: 0.000 acc: 0.000000
e:56/100, 500 loss: 0.000 acc: 0.000000
Training for batch 56 is done
e:57/100, 100 loss: 0.000 acc: 0.000000
e:57/100, 200 loss: 0.000 acc: 0.000000
e:57/100, 300 loss: 0.000 acc: 0.000000
e:57/100, 400 loss: 0.000 acc: 0.000000
e:57/100, 500 loss: 0.000 acc: 0.000000
Training for batch 57 is done
e:58/100, 100 loss: 0.000 acc: 0.000000
e:58/100, 200 loss: 0.000 acc: 0.000000
e:58/100, 300 loss: 0.000 acc: 0.000000
e:58/100, 400 loss: 0.000 acc: 0.000000
e:58/100, 500 loss: 0.000 acc: 0.000000
Training for batch 58 is done
e:59/100, 100 loss: 0.000 acc: 0.000000
e:59/100, 200 loss: 0.000 acc: 0.000000
e:59/100, 300 loss: 0.000 acc: 0.000000
e:59/100, 400 loss: 0.000 acc: 0.000000
e:59/100, 500 loss: 0.000 acc: 0.000000
Training for batch 59 is done
e:60/100, 100 loss: 0.000 acc: 0.000000
e:60/100, 200 loss: 0.000 acc: 0.000000
e:60/100, 300 loss: 0.000 acc: 0.000000
e:60/100, 400 loss: 0.000 acc: 0.000000
e:60/100, 500 loss: 0.000 acc: 0.000000
Training for batch 60 is done
e:61/100, 100 loss: 0.000 acc: 0.000000
e:61/100, 200 loss: 0.000 acc: 0.000000
e:61/100, 300 loss: 0.000 acc: 0.000000
e:61/100, 400 loss: 0.000 acc: 0.000000
e:61/100, 500 loss: 0.000 acc: 0.000000
Training for batch 61 is done
e:62/100, 100 loss: 0.000 acc: 0.000000
e:62/100, 200 loss: 0.000 acc: 0.000000
e:62/100, 300 loss: 0.000 acc: 0.000000
e:62/100, 400 loss: 0.000 acc: 0.000000
e:62/100, 500 loss: 0.000 acc: 0.000000
Training for batch 62 is done
e:63/100, 100 loss: 0.000 acc: 0.000000
e:63/100, 200 loss: 0.000 acc: 0.000000
e:63/100, 300 loss: 0.000 acc: 0.000000
e:63/100, 400 loss: 0.000 acc: 0.000000
e:63/100, 500 loss: 0.000 acc: 0.000000
Training for batch 63 is done
e:64/100, 100 loss: 0.000 acc: 0.000000
e:64/100, 200 loss: 0.000 acc: 0.000000
e:64/100, 300 loss: 0.000 acc: 0.000000
e:64/100, 400 loss: 0.000 acc: 0.000000
e:64/100, 500 loss: 0.000 acc: 0.000000
Training for batch 64 is done
e:65/100, 100 loss: 0.000 acc: 0.000000
e:65/100, 200 loss: 0.000 acc: 0.000000
e:65/100, 300 loss: 0.000 acc: 0.000000
e:65/100, 400 loss: 0.000 acc: 0.000000
e:65/100, 500 loss: 0.000 acc: 0.000000
Training for batch 65 is done
e:66/100, 100 loss: 0.000 acc: 0.000000
e:66/100, 200 loss: 0.000 acc: 0.000000
e:66/100, 300 loss: 0.000 acc: 0.000000
e:66/100, 400 loss: 0.000 acc: 0.000000
e:66/100, 500 loss: 0.000 acc: 0.000000
Training for batch 66 is done
e:67/100, 100 loss: 0.000 acc: 0.000000
e:67/100, 200 loss: 0.000 acc: 0.000000
e:67/100, 300 loss: 0.000 acc: 0.000000
e:67/100, 400 loss: 0.000 acc: 0.000000
e:67/100, 500 loss: 0.000 acc: 0.000000
Training for batch 67 is done
e:68/100, 100 loss: 0.000 acc: 0.000000
e:68/100, 200 loss: 0.000 acc: 0.000000
e:68/100, 300 loss: 0.000 acc: 0.000000
e:68/100, 400 loss: 0.000 acc: 0.000000
e:68/100, 500 loss: 0.000 acc: 0.000000
Training for batch 68 is done
e:69/100, 100 loss: 0.000 acc: 0.000000
e:69/100, 200 loss: 0.000 acc: 0.000000
e:69/100, 300 loss: 0.000 acc: 0.000000
e:69/100, 400 loss: 0.000 acc: 0.000000
e:69/100, 500 loss: 0.000 acc: 0.000000
Training for batch 69 is done
e:70/100, 100 loss: 0.000 acc: 0.000000
e:70/100, 200 loss: 0.000 acc: 0.000000
e:70/100, 300 loss: 0.000 acc: 0.000000
e:70/100, 400 loss: 0.000 acc: 0.000000
e:70/100, 500 loss: 0.000 acc: 0.000000
Training for batch 70 is done
e:71/100, 100 loss: 0.000 acc: 0.000000
e:71/100, 200 loss: 0.000 acc: 0.000000
e:71/100, 300 loss: 0.000 acc: 0.000000
e:71/100, 400 loss: 0.000 acc: 0.000000
e:71/100, 500 loss: 0.000 acc: 0.000000
Training for batch 71 is done
e:72/100, 100 loss: 0.000 acc: 0.000000
e:72/100, 200 loss: 0.000 acc: 0.000000
e:72/100, 300 loss: 0.000 acc: 0.000000
e:72/100, 400 loss: 0.000 acc: 0.000000
e:72/100, 500 loss: 0.000 acc: 0.000000
Training for batch 72 is done
e:73/100, 100 loss: 0.000 acc: 0.000000
e:73/100, 200 loss: 0.000 acc: 0.000000
e:73/100, 300 loss: 0.000 acc: 0.000000
e:73/100, 400 loss: 0.000 acc: 0.000000
e:73/100, 500 loss: 0.000 acc: 0.000000
Training for batch 73 is done
e:74/100, 100 loss: 0.000 acc: 0.000000
e:74/100, 200 loss: 0.000 acc: 0.000000
e:74/100, 300 loss: 0.000 acc: 0.000000
e:74/100, 400 loss: 0.000 acc: 0.000000
e:74/100, 500 loss: 0.000 acc: 0.000000
Training for batch 74 is done
e:75/100, 100 loss: 0.000 acc: 0.000000
e:75/100, 200 loss: 0.000 acc: 0.000000
e:75/100, 300 loss: 0.000 acc: 0.000000
e:75/100, 400 loss: 0.000 acc: 0.000000
e:75/100, 500 loss: 0.000 acc: 0.000000
Training for batch 75 is done
e:76/100, 100 loss: 0.000 acc: 0.000000
e:76/100, 200 loss: 0.000 acc: 0.000000
e:76/100, 300 loss: 0.000 acc: 0.000000
e:76/100, 400 loss: 0.000 acc: 0.000000
e:76/100, 500 loss: 0.000 acc: 0.000000
Training for batch 76 is done
e:77/100, 100 loss: 0.000 acc: 0.000000
e:77/100, 200 loss: 0.000 acc: 0.000000
e:77/100, 300 loss: 0.000 acc: 0.000000
e:77/100, 400 loss: 0.000 acc: 0.000000
e:77/100, 500 loss: 0.000 acc: 0.000000
Training for batch 77 is done
e:78/100, 100 loss: 0.000 acc: 0.000000
e:78/100, 200 loss: 0.000 acc: 0.000000
e:78/100, 300 loss: 0.000 acc: 0.000000
e:78/100, 400 loss: 0.000 acc: 0.000000
e:78/100, 500 loss: 0.000 acc: 0.000000
Training for batch 78 is done
e:79/100, 100 loss: 0.000 acc: 0.000000
e:79/100, 200 loss: 0.000 acc: 0.000000
e:79/100, 300 loss: 0.000 acc: 0.000000
e:79/100, 400 loss: 0.000 acc: 0.000000
e:79/100, 500 loss: 0.000 acc: 0.000000
Training for batch 79 is done
e:80/100, 100 loss: 0.000 acc: 0.000000
e:80/100, 200 loss: 0.000 acc: 0.000000
e:80/100, 300 loss: 0.000 acc: 0.000000
e:80/100, 400 loss: 0.000 acc: 0.000000
e:80/100, 500 loss: 0.000 acc: 0.000000
Training for batch 80 is done
e:81/100, 100 loss: 0.000 acc: 0.000000
e:81/100, 200 loss: 0.000 acc: 0.000000
e:81/100, 300 loss: 0.000 acc: 0.000000
e:81/100, 400 loss: 0.000 acc: 0.000000
e:81/100, 500 loss: 0.000 acc: 0.000000
Training for batch 81 is done
e:82/100, 100 loss: 0.000 acc: 0.000000
e:82/100, 200 loss: 0.000 acc: 0.000000
e:82/100, 300 loss: 0.000 acc: 0.000000
e:82/100, 400 loss: 0.000 acc: 0.000000
e:82/100, 500 loss: 0.000 acc: 0.000000
Training for batch 82 is done
e:83/100, 100 loss: 0.000 acc: 0.000000
e:83/100, 200 loss: 0.000 acc: 0.000000
e:83/100, 300 loss: 0.000 acc: 0.000000
e:83/100, 400 loss: 0.000 acc: 0.000000
e:83/100, 500 loss: 0.000 acc: 0.000000
Training for batch 83 is done
e:84/100, 100 loss: 0.000 acc: 0.000000
e:84/100, 200 loss: 0.000 acc: 0.000000
e:84/100, 300 loss: 0.000 acc: 0.000000
e:84/100, 400 loss: 0.000 acc: 0.000000
e:84/100, 500 loss: 0.000 acc: 0.000000
Training for batch 84 is done
e:85/100, 100 loss: 0.000 acc: 0.000000
e:85/100, 200 loss: 0.000 acc: 0.000000
e:85/100, 300 loss: 0.000 acc: 0.000000
e:85/100, 400 loss: 0.000 acc: 0.000000
e:85/100, 500 loss: 0.000 acc: 0.000000
Training for batch 85 is done
e:86/100, 100 loss: 0.000 acc: 0.000000
e:86/100, 200 loss: 0.000 acc: 0.000000
e:86/100, 300 loss: 0.000 acc: 0.000000
e:86/100, 400 loss: 0.000 acc: 0.000000
e:86/100, 500 loss: 0.000 acc: 0.000000
Training for batch 86 is done
e:87/100, 100 loss: 0.000 acc: 0.000000
e:87/100, 200 loss: 0.000 acc: 0.000000
e:87/100, 300 loss: 0.000 acc: 0.000000
e:87/100, 400 loss: 0.000 acc: 0.000000
e:87/100, 500 loss: 0.000 acc: 0.000000
Training for batch 87 is done
e:88/100, 100 loss: 0.000 acc: 0.000000
e:88/100, 200 loss: 0.000 acc: 0.000000
e:88/100, 300 loss: 0.000 acc: 0.000000
e:88/100, 400 loss: 0.000 acc: 0.000000
e:88/100, 500 loss: 0.000 acc: 0.000000
Training for batch 88 is done
e:89/100, 100 loss: 0.000 acc: 0.000000
e:89/100, 200 loss: 0.000 acc: 0.000000
e:89/100, 300 loss: 0.000 acc: 0.000000
e:89/100, 400 loss: 0.000 acc: 0.000000
e:89/100, 500 loss: 0.000 acc: 0.000000
Training for batch 89 is done
e:90/100, 100 loss: 0.000 acc: 0.000000
e:90/100, 200 loss: 0.000 acc: 0.000000
e:90/100, 300 loss: 0.000 acc: 0.000000
e:90/100, 400 loss: 0.000 acc: 0.000000
e:90/100, 500 loss: 0.000 acc: 0.000000
Training for batch 90 is done
e:91/100, 100 loss: 0.000 acc: 0.000000
e:91/100, 200 loss: 0.000 acc: 0.000000
e:91/100, 300 loss: 0.000 acc: 0.000000
e:91/100, 400 loss: 0.000 acc: 0.000000
e:91/100, 500 loss: 0.000 acc: 0.000000
Training for batch 91 is done
e:92/100, 100 loss: 0.000 acc: 0.000000
e:92/100, 200 loss: 0.000 acc: 0.000000
e:92/100, 300 loss: 0.000 acc: 0.000000
e:92/100, 400 loss: 0.000 acc: 0.000000
e:92/100, 500 loss: 0.000 acc: 0.000000
Training for batch 92 is done
e:93/100, 100 loss: 0.000 acc: 0.000000
e:93/100, 200 loss: 0.000 acc: 0.000000
e:93/100, 300 loss: 0.000 acc: 0.000000
e:93/100, 400 loss: 0.000 acc: 0.000000
e:93/100, 500 loss: 0.000 acc: 0.000000
Training for batch 93 is done
e:94/100, 100 loss: 0.000 acc: 0.000000
e:94/100, 200 loss: 0.000 acc: 0.000000
e:94/100, 300 loss: 0.000 acc: 0.000000
e:94/100, 400 loss: 0.000 acc: 0.000000
e:94/100, 500 loss: 0.000 acc: 0.000000
Training for batch 94 is done
e:95/100, 100 loss: 0.000 acc: 0.000000
e:95/100, 200 loss: 0.000 acc: 0.000000
e:95/100, 300 loss: 0.000 acc: 0.000000
e:95/100, 400 loss: 0.000 acc: 0.000000
e:95/100, 500 loss: 0.000 acc: 0.000000
Training for batch 95 is done
e:96/100, 100 loss: 0.000 acc: 0.000000
e:96/100, 200 loss: 0.000 acc: 0.000000
e:96/100, 300 loss: 0.000 acc: 0.000000
e:96/100, 400 loss: 0.000 acc: 0.000000
e:96/100, 500 loss: 0.000 acc: 0.000000
Training for batch 96 is done
e:97/100, 100 loss: 0.000 acc: 0.000000
e:97/100, 200 loss: 0.000 acc: 0.000000
e:97/100, 300 loss: 0.000 acc: 0.000000
e:97/100, 400 loss: 0.000 acc: 0.000000
e:97/100, 500 loss: 0.000 acc: 0.000000
Training for batch 97 is done
e:98/100, 100 loss: 0.000 acc: 0.000000
e:98/100, 200 loss: 0.000 acc: 0.000000
e:98/100, 300 loss: 0.000 acc: 0.000000
e:98/100, 400 loss: 0.000 acc: 0.000000
e:98/100, 500 loss: 0.000 acc: 0.000000
Training for batch 98 is done
e:99/100, 100 loss: 0.000 acc: 0.000000
e:99/100, 200 loss: 0.000 acc: 0.000000
e:99/100, 300 loss: 0.000 acc: 0.000000
e:99/100, 400 loss: 0.000 acc: 0.000000
e:99/100, 500 loss: 0.000 acc: 0.000000
Training for batch 99 is done
CW_kappa: 0
alpha: 1.0
beta: 0.0
gamma: 0.0
nr_epoch: 500
targeted_attack: False
use_cross_entropy_loss: False
Success rate: 1.0
Noise l1-norm: 21.82541286468506
Noise l2-norm: 0.44578651294112204
Noise l-inf: 0.00862745134625584
